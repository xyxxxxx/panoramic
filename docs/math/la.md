# 线性代数

## 特征分解

## 奇异值分解（SVD）

对于 $m×n$ 阶矩阵 $A$，其元素全部属于实数域，则存在一个分解使得：

$$
A=UΣV^{\rm T}
$$

其中 $U$ 是 $m$ 阶正交矩阵，$Σ$ 是 $m×n$ 阶非负实数对角矩阵，$V^{\rm T}$ 是 $n$ 阶正交矩阵。这样的分解称为 $M$ 的**奇异值分解**，$Σ$ 对角线上的元素为 $M$ 的**奇异值**，$U$ 和 $V$ 的列分别为 $M$ 的**左奇异向量**和**右奇异向量**。

实践中，通常将奇异值从大到小排列，这样 $Σ$ 便能由 $M$ 唯一确定（虽然 $U$ 和 $V$ 仍不能唯一确定）。

## 理解

**线性变换**

$m×n$ 阶矩阵 $A$ 是一个线性变换，其将任意一个 $n$ 维向量转换为一个 $m$ 维向量。$A=UΣV^{\rm T}$ 可以理解为，任意一个线性变换可以拆分为 3 个线性变换的组合：先在 $n$ 维空间旋转，再升降维拉伸到 $m$ 维空间（减少的维度被移除，增加的维度初始化为 0；拉伸只能沿基的方向），再在 $m$ 维空间旋转。

**数据分析**

$m×n$ 阶矩阵 $A$ 是一个数据表，其行和列可能分别代表时间和空间、商品和属性等。$A=UΣV^{\rm T}=σ_1\pmb u_1\pmb v_1^{\rm T}+σ_2\pmb u_2\pmb v_2^{\rm T}+\cdots$ 可以理解为，每个 $σ_i\pmb u_i\pmb v_i^{\rm T}$ 是一个模式，$\pmb u_i$ 是模式对于每一行的分配比例（单位向量），$\pmb v_i$ 是模式对于每一行的分配比例，$σ_i$ 是模式的系数。丢弃末尾的几个系数较小的模式，即为一种数据降维压缩的方法。

![](https://s2.loli.net/2024/12/26/w4CFu5pIn7PK8af.png)

## 计算

由于：

$$
AA^{\rm T}=UΣV^{\rm T}VΣ^{\rm T}U^{\rm T}=UΣΣ^{\rm T}U^{\rm T}
$$

其中 $AA^{\rm T}$ 是 $m$ 阶方阵，$U$ 是 $m$ 阶正交矩阵，$ΣΣ^{\rm T}$ 是 $m$ 阶非负对角方阵。因此对 $AA^{\rm T}$ 作特征分解，即得到 $U$ 和 $Σ$。左奇异向量是 $AA^{\rm T}$ 的特征向量，奇异值是 $AA^{\rm T}$ 的特征值的非负平方根。

同理，对 $A^{\rm T}A$ 作特征分解，即得到 $V$ 和 $Σ$。右奇异向量是 $A^{\rm T}A$ 的特征向量，奇异值也是 $A^{\rm T}A$ 的特征值的非负平方根。
